{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97abf1e0-aaa1-4e70-a33e-f29e928904bc",
   "metadata": {},
   "source": [
    "# MPC with MjWarp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28113581-cd10-4465-8eaf-e7df00fea01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# jupyter notebook --NotebookApp.allow_origin='https://colab.research.google.com' --port=8888 --NotebookApp.port_retries=0 --no-browser\n",
    "\n",
    "from brax import base as brax_base\n",
    "from brax.io import html\n",
    "from brax.io import mjcf\n",
    "import jax\n",
    "from jax import numpy as jnp\n",
    "from IPython.display import HTML\n",
    "import mujoco\n",
    "from mujoco import mjx\n",
    "from mujoco.mjx._src import dataclasses\n",
    "import mujoco_warp as mjwarp\n",
    "import mediapy as media\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import tqdm\n",
    "from typing import Callable\n",
    "import warp as wp\n",
    "from warp.jax_experimental.ffi import jax_callable\n",
    "\n",
    "# this ensures JAX embeds Warp kernels into its own computation graph:\n",
    "os.environ[\"XLA_FLAGS\"] = \"--xla_gpu_graph_min_graph_size=1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca94fb9-04e3-4b21-b34c-4dfc092ac4b6",
   "metadata": {},
   "source": [
    "# Humanoid Stand Up Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3877c7-49cb-4ddf-9973-6496fe66cc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting MuJoCo humanoid XML description from GitHub:\n",
      "fatal: destination path 'mujoco' already exists and is not an empty directory.\n",
      "Warp 1.8.0.dev20250428 initialized:\n",
      "   Git commit: c742435d2338dbc68b606dfb347c8931759e88a3\n",
      "   CUDA Toolkit 12.8, Driver 12.8\n",
      "   Devices:\n",
      "     \"cpu\"      : \"CPU\"\n",
      "     \"cuda:0\"   : \"NVIDIA RTX A4000\" (16 GiB, sm_86, mempool enabled)\n",
      "   Kernel cache:\n",
      "     /usr/local/google/home/tjpower/.cache/warp/1.8.0.dev20250428\n"
     ]
    }
   ],
   "source": [
    "NCONMAX = 81920\n",
    "NJMAX = NCONMAX * 4\n",
    "NWORLDS = 1024\n",
    "HORIZON = 128\n",
    "NSTEPS = 1000\n",
    "PLAN_EVERY = 10\n",
    "\n",
    "# Get MuJoCo's humanoid model.\n",
    "print('Getting MuJoCo humanoid XML description from GitHub:')\n",
    "!git clone https://github.com/google-deepmind/mujoco\n",
    "humanoid_file = 'mujoco/model/humanoid/humanoid.xml'\n",
    "spec = mujoco.MjSpec.from_file(humanoid_file)\n",
    "\n",
    "spec.option.jacobian = mujoco.mjtJacobian.mjJAC_SPARSE\n",
    "spec.option.integrator = mujoco.mjtIntegrator.mjINT_RK4\n",
    "\n",
    "# Initialise to squat position\n",
    "mjm = spec.compile()\n",
    "mjm.opt.iterations = 1\n",
    "mjm.opt.ls_iterations = 4\n",
    "mjd = mujoco.MjData(mjm)\n",
    "key = mjm.key('squat').id\n",
    "mujoco.mj_resetDataKeyframe(mjm, mjd, key)\n",
    "\n",
    "# make warp model/data\n",
    "m = mjwarp.put_model(mjm)\n",
    "d = mjwarp.put_data(mjm, mjd, nworld=NWORLDS, nconmax=131012, njmax=131012 * 4)\n",
    "\n",
    "# make jax model/data\n",
    "mjxm = mjx.put_model(mjm) \n",
    "mjxd = mjx.put_data(mjm, mjd)\n",
    "mjxd = mjx.kinematics(mjxm, mjxd)\n",
    "\n",
    "# Cost \n",
    "def cost_fn(qpos, qvel, ctrl):\n",
    "  # body position\n",
    "  body_pos = qpos[..., :3]\n",
    "  body_quat = qpos[..., 3:7]\n",
    "  target_body_pos = jnp.array([[0.0, 0.0, 1.2]])\n",
    "  target_body_weight = jnp.array([0.1, 0.1, 1.0])\n",
    "  pos_cost = jnp.dot(\n",
    "      (body_pos - target_body_pos) ** 2,\n",
    "      target_body_weight\n",
    "  )\n",
    "  vel_cost = jnp.sum(qvel**2, axis=-1).reshape(-1)\n",
    "  return 100 * pos_cost\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2ccc59-7782-43cb-81e2-4e3f71ac37c1",
   "metadata": {},
   "source": [
    "# Define MPPI Planner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97f40f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "CostFn = Callable[[jax.Array, jax.Array, jax.Array], jax.Array]\n",
    "StepFn = Callable[[jax.Array, jax.Array, jax.Array], tuple[jax.Array, jax.Array]]\n",
    "\n",
    "class MPPIConfig(dataclasses.PyTreeNode):\n",
    "  \"\"\"Planning Config.\n",
    "\n",
    "  Attributes:\n",
    "    model: MJX model\n",
    "    cost: function returning per-timestep cost\n",
    "    step_fn: function for stepping simulation during rollout\n",
    "    noise_scale: standard deviation of zero-mean Gaussian\n",
    "    horizon: planning duration (steps)\n",
    "    nspline: number of spline points to explore\n",
    "    nsample: number of action sequence candidates sampled\n",
    "    interp: type of action interpolation\n",
    "    inverse_temperature: MPPI inverse temperature\n",
    "  \"\"\"\n",
    "  model: mjx.Model\n",
    "  cost: CostFn\n",
    "  step_fn: StepFn\n",
    "  noise_scale: float\n",
    "  horizon: int\n",
    "  nspline: int\n",
    "  nsample: int\n",
    "  interp: str\n",
    "  inverse_temperature: float\n",
    "\n",
    "class MPPIPlanner:\n",
    "\n",
    "  def __init__(self,\n",
    "              model: mjx.Model,\n",
    "              cost: CostFn,\n",
    "              step_fn: StepFn,\n",
    "              noise_scale: float,\n",
    "              horizon: int,\n",
    "              nspline: int,\n",
    "              nsample: int,\n",
    "              interp: str,\n",
    "              inverse_temperature: float,\n",
    "              ) -> None:\n",
    "\n",
    "    self._config = MPPIConfig (\n",
    "      cost = cost,\n",
    "      model = model,\n",
    "      step_fn = step_fn,\n",
    "      noise_scale = noise_scale,\n",
    "      horizon = horizon,\n",
    "      nsample = nsample,\n",
    "      nspline = nspline,\n",
    "      interp = interp,\n",
    "      inverse_temperature = inverse_temperature,\n",
    "    )\n",
    "      \n",
    "  @property\n",
    "  def config(self) -> MPPIConfig:\n",
    "    return self._config\n",
    "\n",
    "  @staticmethod\n",
    "  def get_actions(p: MPPIConfig, policy: jax.Array) -> jax.Array:\n",
    "    \"\"\"Gets actions over a planning duration from a policy.\"\"\"\n",
    "    if p.interp == 'zero':\n",
    "      indices = [i * p.nspline // p.horizon for i in range(p.horizon)]\n",
    "      actions = policy[jnp.array(indices)]\n",
    "    elif p.interp == 'linear':\n",
    "      locs = jnp.array([i * p.nspline / p.horizon for i in range(p.horizon)])\n",
    "      idx = locs.astype(int)\n",
    "      actions = jax.vmap(jnp.multiply)(policy[idx], 1 - locs + idx)\n",
    "      actions += jax.vmap(jnp.multiply)(policy[idx + 1], locs - idx)\n",
    "    else:\n",
    "      raise ValueError(f'unimplemented interpolation method: {p.interp}')\n",
    "    return actions\n",
    "\n",
    "  @staticmethod\n",
    "  def rollout(p: MPPIConfig, qpos: jax.Array, \n",
    "              qvel:jax.Array, policy: jax.Array) -> jax.Array:\n",
    "    \"\"\"Expand the policy into actions and roll out dynamics and cost.\"\"\"\n",
    "\n",
    "    B, H, _ = policy.shape\n",
    "    qpos = jnp.tile(qpos, (B, 1))\n",
    "    qvel = jnp.tile(qvel, (B, 1))\n",
    "    actions = jax.vmap(MPPIPlanner.get_actions, in_axes=(None, 0))(p, policy)\n",
    "\n",
    "    def step(carry, u):\n",
    "      qpos, qvel = carry\n",
    "      qpos, qvel = p.step_fn(qpos, qvel, u)\n",
    "      cost = p.cost(qpos, qvel, u)\n",
    "      return (qpos, qvel), (qpos, qvel, cost)\n",
    "\n",
    "    _, (qpos_traj, qvel_traj, costs) = jax.lax.scan(step, (qpos, qvel), actions.transpose(1, 0, 2))\n",
    "\n",
    "\n",
    "    return jnp.sum(costs, axis=0)\n",
    "\n",
    "  @staticmethod\n",
    "  def resample(p: MPPIConfig, policy: jax.Array, steps_per_plan: int) -> jax.Array:\n",
    "    \"\"\"Resample policy to new advanced time.\"\"\"\n",
    "    if p.interp == 'zero':\n",
    "      return policy  # assuming steps_per_plan < splinesteps\n",
    "    elif p.interp == 'linear':\n",
    "      actions = MPPIPlanner.get_actions(p, policy)\n",
    "      roll = steps_per_plan\n",
    "      actions = jnp.roll(actions, -roll, axis=-2)\n",
    "      actions = actions.at[..., -roll:, :].set(actions[..., [-1], :])\n",
    "      idx = jnp.floor(jnp.linspace(0, p.horizon, p.nspline)).astype(int)\n",
    "      return actions[..., idx, :]\n",
    "    return policy\n",
    "\n",
    "  @staticmethod\n",
    "  def improve_policy(\n",
    "      p: MPPIConfig,\n",
    "      qpos: jax.Array,\n",
    "      qvel: jax.Array,\n",
    "      policy: jax.Array,\n",
    "      rng: jax.Array,\n",
    "  ) -> tuple[jax.Array, jax.Array]:\n",
    "    \"\"\"Improves policy.\"\"\"\n",
    "    # create noisy policies\n",
    "    noise = (\n",
    "        jax.random.normal(rng, (p.nsample, p.nspline, p.model.nu)) * p.noise_scale\n",
    "    )\n",
    "    policies = policy + noise\n",
    "\n",
    "    # clamp actions to ctrlrange\n",
    "    limit = p.model.actuator_ctrlrange\n",
    "    policies = jnp.clip(policies, limit[:, 0], limit[:, 1])\n",
    "\n",
    "    # perform parallel rollouts\n",
    "    costs = MPPIPlanner.rollout(p, qpos, qvel, policies)\n",
    "    costs = jnp.nan_to_num(costs, nan=jnp.inf)\n",
    "\n",
    "    # add perturbation cost\n",
    "    perturb_cost = jnp.sum(p.inverse_temperature * noise *\n",
    "                           policies / p.noise_scale**2, axis=(1, 2))\n",
    "    costs += perturb_cost\n",
    "\n",
    "    # normalize cost to [0, 1]\n",
    "    costs /= jnp.max(costs) - jnp.min(costs)\n",
    "    costs -= jnp.min(costs)\n",
    "\n",
    "    # compute update weights\n",
    "    omega = jax.nn.softmax(-costs / p.inverse_temperature)\n",
    "\n",
    "    # get final nominal\n",
    "    policy = jnp.einsum('i,ijk->jk', omega, policies)\n",
    "    return policy\n",
    "\n",
    "\n",
    "def mpc_rollout(\n",
    "    nsteps,\n",
    "    steps_per_plan,\n",
    "    p: MPPIPlanner,\n",
    "    init_policy,\n",
    "    rng,\n",
    "    model,\n",
    "    data,\n",
    "):\n",
    "  \"\"\"Receding horizon optimization starting from sim_data's state.\"\"\"\n",
    "  qpos = np.zeros((nsteps, model.nq))\n",
    "  qvel = np.zeros((nsteps, model.nv))\n",
    "  costs = np.zeros(nsteps)\n",
    "    \n",
    "  policy = init_policy.clone()\n",
    "  for step in tqdm.tqdm(range(nsteps // steps_per_plan)):\n",
    "\n",
    "    # resample\n",
    "    policy = jax.jit(p.resample, static_argnums=(2))(p.config, policy, steps_per_plan)\n",
    "    # planning\n",
    "    policy = jax.jit(p.improve_policy)(\n",
    "        p.config,\n",
    "        data.qpos,\n",
    "        data.qvel,\n",
    "        policy,\n",
    "        rng,\n",
    "    )\n",
    "    # get actions from spline\n",
    "    actions = jax.jit(p.get_actions)(p.config, policy)\n",
    "\n",
    "    # rollout\n",
    "    for i in range(steps_per_plan):\n",
    "      action = actions[i]\n",
    "      data = data.replace(ctrl=action)\n",
    "      costs[step * steps_per_plan + i] = p.config.cost(data.qpos, data.qvel, action)[0]\n",
    "      data = jax.jit(mjx.step)(model, data)\n",
    "      qpos[step * steps_per_plan + i] = data.qpos\n",
    "      qvel[step * steps_per_plan + i] = data.qvel\n",
    "        \n",
    "  return qpos, qvel, costs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab40687a-e990-4904-8a83-0c14c275c91f",
   "metadata": {},
   "source": [
    "# Using mjwarp.step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53309db5-ba50-4980-a497-0cefa059cf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step fn\n",
    "def warp_step(\n",
    "  qpos_in: wp.array(dtype=wp.float32, ndim=2),\n",
    "  qvel_in: wp.array(dtype=wp.float32, ndim=2),\n",
    "  ctrl_in: wp.array(dtype=wp.float32, ndim=2),\n",
    "  qpos_out: wp.array(dtype=wp.float32, ndim=2),\n",
    "  qvel_out: wp.array(dtype=wp.float32, ndim=2),\n",
    "):\n",
    "  wp.copy(d.qpos, qpos_in)\n",
    "  wp.copy(d.qvel, qvel_in)\n",
    "  wp.copy(d.ctrl, ctrl_in)\n",
    "  mjwarp.step(m, d)\n",
    "  wp.copy(qpos_out, d.qpos)\n",
    "  wp.copy(qvel_out, d.qvel)\n",
    "\n",
    "warp_step_fn = jax_callable(\n",
    "  warp_step,\n",
    "  num_outputs=2,\n",
    "  output_dims={\"qpos_out\": (NWORLDS, mjm.nq), \"qvel_out\": (NWORLDS, mjm.nv)},\n",
    ")\n",
    "\n",
    "# Instantiate the planner\n",
    "warp_planner = MPPIPlanner(\n",
    "    model=mjxm,\n",
    "    step_fn = warp_step_fn,\n",
    "    cost=cost_fn,\n",
    "    noise_scale=2.0,\n",
    "    horizon=HORIZON,\n",
    "    nspline=16,\n",
    "    nsample=NWORLDS,\n",
    "    interp='zero',\n",
    "    inverse_temperature=0.01\n",
    ")\n",
    "\n",
    "rng = jax.random.PRNGKey(0)\n",
    "planner_params = warp_planner.config\n",
    "policy = jnp.zeros((planner_params.nspline, planner_params.model.nu))\n",
    "\n",
    "# Run once to compile\n",
    "beg = time.perf_counter()\n",
    "jax.block_until_ready(mpc_rollout(1, 1, warp_planner, policy,\n",
    "                                rng, mjx.put_model(mjm),\n",
    "                                mjx.put_data(mjm, mjd)\n",
    "                                 )\n",
    "                     )\n",
    "end = time.perf_counter()\n",
    "print(f\"Jit time: {end-beg}.4f\")\n",
    "\n",
    "qpos, qvel, costs = mpc_rollout(NSTEPS, PLAN_EVERY, warp_planner, policy,\n",
    "                                rng, mjx.put_model(mjm),\n",
    "                                mjx.put_data(mjm, mjd))\n",
    "\n",
    "# # # now let's render the model into a video\n",
    "d = mujoco.MjData(mjm)\n",
    "sys = mjcf.load_model(mjm)\n",
    "xstates = []\n",
    "for qp in qpos.reshape(-1, mjm.nq):\n",
    "  d.qpos = qp\n",
    "  mujoco.mj_kinematics(mjm, d)\n",
    "  x = brax_base.Transform(pos=d.xpos[1:].copy(), rot=d.xquat[1:].copy())\n",
    "  xstates.append(brax_base.State(q=None, qd=None, x=x, xd=None, contact=None))\n",
    "\n",
    "HTML(html.render(sys, xstates))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7d52eb-ae76-4f15-a764-038c31092bbe",
   "metadata": {},
   "source": [
    "# Using mjx.step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671cdd32-4e5c-421b-ba74-649df02c01e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [01:43<00:00, 103.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jit time: 103.6063076879982.4f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                           | 56/100 [01:54<01:30,  2.06s/it]"
     ]
    }
   ],
   "source": [
    "def mjx_step_fn(\n",
    "    qpos_in: jax.Array,\n",
    "    qvel_in: jax.Array,\n",
    "    ctrl_in: jax.Array,\n",
    ") -> tuple[jax.Array, jax.Array]:\n",
    "  global mjxd\n",
    "  mjxd = mjxd.replace(qpos=qpos_in, qvel=qvel_in, ctrl=ctrl_in)\n",
    "  mjxd = mjx.step(mjxm, mjxd)\n",
    "  return mjxd.qpos, mjxd.qvel\n",
    "\n",
    "mjx_step_fn = jax.vmap(mjx_step_fn)\n",
    "\n",
    "# Instantiate the planner\n",
    "mjx_planner = MPPIPlanner(\n",
    "    model=mjxm,\n",
    "    step_fn = mjx_step_fn,\n",
    "    cost=cost_fn,\n",
    "    noise_scale=2.0,\n",
    "    horizon=HORIZON,\n",
    "    nspline=16,\n",
    "    nsample=NWORLDS,\n",
    "    interp='zero',\n",
    "    inverse_temperature=0.01\n",
    ")\n",
    "rng = jax.random.PRNGKey(0)\n",
    "planner_params = warp_planner.config\n",
    "policy = jnp.zeros((planner_params.nspline, planner_params.model.nu))\n",
    "\n",
    "# Run once to compile\n",
    "beg = time.perf_counter()\n",
    "jax.block_until_ready(mpc_rollout(1, 1, mjx_planner, policy,\n",
    "                                rng, mjx.put_model(mjm),\n",
    "                                mjx.put_data(mjm, mjd)\n",
    "                                 )\n",
    "                     )\n",
    "end = time.perf_counter()\n",
    "print(f\"Jit time: {end-beg}.4f\")\n",
    "\n",
    "# do loop\n",
    "qpos, qvel, costs = mpc_rollout(NSTEPS, PLAN_EVERY, mjx_planner, policy,\n",
    "                                rng, mjx.put_model(mjm), mjx.put_data(mjm, mjd))\n",
    "\n",
    "# # # now let's render the model into a video\n",
    "d = mujoco.MjData(mjm)\n",
    "sys = mjcf.load_model(mjm)\n",
    "xstates = []\n",
    "for qp in qpos.reshape(-1, mjm.nq):\n",
    "  d.qpos = qp\n",
    "  mujoco.mj_kinematics(mjm, d)\n",
    "  x = brax_base.Transform(pos=d.xpos[1:].copy(), rot=d.xquat[1:].copy())\n",
    "  xstates.append(brax_base.State(q=None, qd=None, x=x, xd=None, contact=None))\n",
    "\n",
    "HTML(html.render(sys, xstates))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
